{
  "bugs": {
    "tasks": [
      {
        "id": 1,
        "title": "Fix Frontend TypeScript Errors in Test Files",
        "description": "Resolve TypeScript type errors in several frontend test files (UnsoldProductsForm.test.tsx, RecipeForm.test.tsx, ThemeContext.test.tsx) to ensure the test suite compiles successfully.",
        "details": "The goal of this task is to eliminate all TypeScript compilation errors originating from the specified test files. Start by running `npx tsc --noEmit` or `npm test` to see the full list of errors. Address the errors in each file by ensuring that mocked props, context values, and test data structures correctly match their corresponding type definitions.\n\n1.  **UnsoldProductsForm.test.tsx**: Investigate type mismatches for props being passed to the component within the tests. This likely involves form handlers (`onSubmit`), form state, or initial data. Ensure any mocked functions or objects align with the component's prop types.\n2.  **RecipeForm.test.tsx**: Similar to the above, focus on correcting the types for mocked props, especially for complex data structures like ingredients or recipe steps. If custom hooks are used, ensure their mocked return values are correctly typed.\n3.  **ThemeContext.test.tsx**: The errors are likely related to the value provided to the `ThemeContext.Provider` in the test setup. Ensure the mock context object matches the defined context type, including all its properties (e.g., `theme`, `toggleTheme`).\n\nAvoid using `any` or `@ts-ignore` as a solution. Instead, use proper types, interfaces, or TypeScript utility types like `Partial` or `jest.Mock` to correctly type test-specific implementations.",
        "testStrategy": "1. Run the TypeScript compiler across the entire project (`npx tsc --noEmit`) and confirm it completes with no errors.\n2. Execute the full frontend test suite (`npm test` or `yarn test`) and verify that all tests pass without any compilation warnings or errors.\n3. Specifically run the tests for the modified files to isolate and confirm the fix:\n   - `npm test -- UnsoldProductsForm.test.tsx`\n   - `npm test -- RecipeForm.test.tsx`\n   - `npm test -- ThemeContext.test.tsx`\n4. Ensure no new linting errors have been introduced by running the linter (`npm run lint`).",
        "status": "pending",
        "dependencies": [],
        "priority": "high",
        "subtasks": []
      },
      {
        "id": 2,
        "title": "Fix Backend Test Failures",
        "description": "Resolve 13 failing tests across the Cash, Auth, and UnsoldProduct controllers to ensure the backend test suite passes successfully.",
        "details": "The goal of this task is to identify the root cause of and fix 13 failing tests located in `authController.test.js`, `cashController.test.js`, and `unsoldProductController.test.js`. Start by running the backend test suite to get a detailed report of the failures. Address the failing tests in each file systematically:\n\n1.  **authController.test.js**: Investigate failures related to user authentication and authorization. Common issues include incorrect mocking of request objects, problems with password hashing/comparison mocks, or invalid JWT generation/verification logic in the test environment.\n2.  **cashController.test.js**: Examine tests for cash transaction logic. Failures may be due to incorrect database state setup (e.g., using a test database seeder), floating-point precision issues in financial calculations, or improper mocking of dependent services.\n3.  **unsoldProductController.test.js**: Debug tests related to unsold product management. Check for issues with mocking product data, user permissions for CRUD operations, or logic that depends on dates and times which might be mocked incorrectly.\n\nUse debugging tools and add console logs as necessary to inspect state and variables at the point of failure. Ensure that fixes do not introduce regressions in other tests.",
        "testStrategy": "1. Navigate to the backend directory and run the entire test suite (e.g., `npm test` or `jest`). Confirm that the initial run reports exactly 13 failures in the specified files.\n2. After implementing the fixes, run the entire test suite again. Verify that all tests now pass and there are zero failures.\n3. Run the tests for each affected file individually to confirm they pass in isolation (e.g., `jest authController.test.js`).\n4. Ensure that the code coverage report, if configured, has not decreased significantly.",
        "status": "pending",
        "dependencies": [],
        "priority": "high",
        "subtasks": []
      }
    ],
    "metadata": {
      "created": "2025-07-31T14:20:46.724Z",
      "updated": "2025-07-31T14:21:44.748Z",
      "description": "Bug fixes and issues"
    }
  },
  "improvements": {
    "tasks": [
      {
        "id": 1,
        "title": "Implement Chat Frontend Components and Admin Page",
        "description": "Create the necessary frontend components for the real-time chat feature and integrate them into a new chat page within the admin interface. This task involves building the UI to interact with the existing /chat backend API.",
        "details": "1. **Component Scaffolding:** Create the following React components inside `/src/components/admin/chat/`:\n   - `ChatPage.js`: The main container component that orchestrates the other chat components.\n   - `ConversationList.js`: A sidebar component to display and select from a list of active chat conversations. Fetches data from `GET /chat/conversations`.\n   - `ChatWindow.js`: The main view that displays messages for the selected conversation. It will contain `MessageList` and `MessageInput`.\n   - `MessageList.js`: Renders a list of individual message components. Should handle scrolling to the latest message.\n   - `Message.js`: Renders a single chat message, potentially with different styles for sender vs. receiver.\n   - `MessageInput.js`: A form with a text input and a 'Send' button to post new messages via `POST /chat/conversations/:id/messages`.\n\n2. **State Management:** Use React hooks (`useState`, `useEffect`, `useContext`) to manage the application state, including the list of conversations, the currently selected conversation, and the messages for that conversation.\n\n3. **API Integration:** Use `axios` or `fetch` to interact with the backend API endpoints:\n   - On initial load of `ChatPage`, fetch the list of conversations.\n   - When a conversation is selected from `ConversationList`, fetch its message history using `GET /chat/conversations/:id/messages`.\n   - Implement the send message functionality in `MessageInput` to post to the backend.\n   - Implement basic error handling and loading states for all API calls.\n\n4. **Routing and Navigation:**\n   - Add a new route for `/admin/chat` in the application's router that renders the `ChatPage` component.\n   - Add a link to '/admin/chat' in the main admin navigation menu/sidebar for easy access.\n\n5. **Styling:**\n   - Apply styles consistent with the existing admin interface design system.\n   - Ensure the layout is responsive and functional on both desktop and mobile screen sizes. The chat interface should be intuitive, with a clear distinction between sent and received messages.",
        "testStrategy": "1. **Navigation and Rendering:**\n   - Navigate to the `/admin/chat` URL directly. Verify the `ChatPage` component loads without errors.\n   - Click the new 'Chat' link in the admin navigation sidebar and confirm it routes to the correct page.\n   - Verify that the `ConversationList`, `ChatWindow`, and `MessageInput` components are all rendered on the page.\n\n2. **Functionality Verification:**\n   - **Load Conversations:** Confirm that the `ConversationList` is populated with a list of conversations from the backend API. Check the browser's network tab to verify the `GET /chat/conversations` call is successful.\n   - **Select Conversation:** Click on a conversation in the list. Verify that the `ChatWindow` updates to show the messages for that conversation. Check the network tab for a successful `GET /chat/conversations/:id/messages` call.\n   - **Send a Message:** Select a conversation, type a message into the `MessageInput` field, and click 'Send'.\n     - Verify a `POST` request is sent to the correct endpoint with the correct payload.\n     - The new message should immediately appear in the `MessageList`.\n     - The input field should be cleared after sending.\n   - **UI Behavior:**\n     - Confirm that the `MessageList` automatically scrolls to the bottom when a new message is sent or received.\n     - Test with an empty conversation to ensure a 'no messages yet' state is displayed correctly.\n\n3. **Edge Cases and Error Handling:**\n   - Simulate an API failure for fetching conversations or messages. Verify that a user-friendly error message is displayed.\n   - Attempt to send an empty message. Verify that the message is not sent and appropriate user feedback is provided.\n   - Check responsiveness by resizing the browser window to mobile and tablet sizes. Ensure the layout adjusts correctly and remains usable.",
        "status": "pending",
        "dependencies": [],
        "priority": "medium",
        "subtasks": []
      },
      {
        "id": 2,
        "title": "Verify and Update Dashboard Analytics Integration",
        "description": "Verify the live data connection between the dashboard frontend and the analytics backend controller, and update the `FRONTEND_BACKEND_INTEGRATION_TODO.md` documentation to reflect the correct integration status.",
        "details": "1. **Investigation:** In the frontend codebase, identify the dashboard components responsible for displaying analytics data. Trace the data fetching logic to find the specific API endpoints being called.\n2. **Verification:** Using browser developer tools, monitor network traffic on the dashboard page. Confirm that API calls are made to the live backend routes (e.g., `/api/dashboard/analytics`) and not a mock service. Check for successful (2xx) status codes.\n3. **Data Validation:** Inspect the JSON response from the backend. Ensure the data structure matches the frontend component's expectations and that the data appears to be dynamic, not static.\n4. **Documentation Update:** Locate the `FRONTEND_BACKEND_INTEGRATION_TODO.md` file in the project root. Change the status for the dashboard analytics feature from 'MOCK DATA ONLY' to 'VERIFIED - FULLY INTEGRATED'.\n5. **Commit:** Commit the changes to the markdown file with a clear message, e.g., 'docs: Update dashboard integration status to verified'.",
        "testStrategy": "1. **Load Dashboard:** Navigate to the application's main dashboard page.\n2. **Inspect Network:** Open browser developer tools and monitor the Network tab. Verify that API requests to the analytics endpoints are successful and return non-static data.\n3. **UI Confirmation:** Confirm that all dashboard charts, graphs, and statistics are populated correctly with the data received from the API.\n4. **Review Documentation:** Pull the latest changes from the repository and open `FRONTEND_BACKEND_INTEGRATION_TODO.md`. Confirm that the entry for dashboard analytics has been updated correctly and no longer says 'MOCK DATA ONLY'.",
        "status": "pending",
        "dependencies": [],
        "priority": "medium",
        "subtasks": []
      },
      {
        "id": 3,
        "title": "Create User Management Admin UI",
        "description": "Develop a new section in the admin panel at /admin/users to provide full CRUD (Create, Read, Update, Delete) functionality for user accounts. This interface will also allow administrators to manage user roles.",
        "details": "1. **API Integration:** This task assumes the following backend API endpoints are available. Confirm their existence and contracts:\n   - `GET /api/admin/users`: To fetch a paginated list of all users.\n   - `POST /api/admin/users`: To create a new user.\n   - `GET /api/admin/users/{userId}`: To fetch details for a single user for the edit form.\n   - `PUT /api/admin/users/{userId}`: To update a user's details (e.g., name, email, role).\n   - `DELETE /api/admin/users/{userId}`: To delete a user.\n   - `GET /api/admin/roles`: To fetch a list of available user roles for the form dropdown.\n\n2. **Component Development:** Create the following React components under `/src/components/admin/users/`:\n   - `UserListPage.js`: The main container component for the `/admin/users` route. It will manage state and orchestrate data fetching for the user list.\n   - `UserTable.js`: A reusable component that displays users in a table. It should support pagination, sorting, and filtering. Columns should include User ID, Name, Email, Role, and an 'Actions' column with Edit/Delete buttons.\n   - `UserForm.js`: A form for both creating and editing users. It should include fields for name, email, password (on create only), and a dropdown to select a user role. Implement client-side validation for all fields.\n   - `DeleteUserModal.js`: A confirmation modal to prevent accidental user deletion.\n\n3. **Routing:**\n   - Add a new route for `/admin/users` that renders the `UserListPage` component.\n   - Add a link to 'User Management' in the main admin navigation sidebar.\n   - Implement nested routes for creating (`/admin/users/new`) and editing (`/admin/users/edit/:userId`) users, both of which will render the `UserForm` component.\n\n4. **State Management:** Use the existing state management solution (e.g., Redux, Context API) to handle the user list, loading states, and API errors gracefully.",
        "testStrategy": "1. **List & Read:**\n   - Navigate to `/admin/users`. Verify the page loads and the user table is populated with data from the API.\n   - Test the pagination controls to ensure they correctly fetch and display different pages of users.\n   - Test the search/filter functionality to ensure the user list is correctly filtered.\n\n2. **Create:**\n   - Click the 'Create User' button and verify it navigates to the user creation form.\n   - Attempt to submit the form with invalid data (e.g., bad email format, empty required fields) and verify that validation errors are displayed.\n   - Fill out the form with valid data and submit. Verify the user is successfully created, a success notification is shown, and the new user appears in the table on the main list page.\n\n3. **Update:**\n   - From the user table, click the 'Edit' button for a specific user.\n   - Verify the edit form loads and is pre-populated with that user's data.\n   - Modify the user's name and role, then save the changes.\n   - Verify the user's information is updated in the main user table.\n\n4. **Delete:**\n   - Click the 'Delete' button for a user.\n   - Verify that a confirmation modal appears.\n   - Click 'Cancel' and verify the modal closes and the user is not deleted.\n   - Click 'Delete' again, then 'Confirm' in the modal. Verify the user is removed from the user table and a success message is shown.",
        "status": "pending",
        "dependencies": [],
        "priority": "medium",
        "subtasks": []
      }
    ],
    "metadata": {
      "created": "2025-07-31T14:21:52.668Z",
      "updated": "2025-07-31T14:23:42.502Z",
      "description": "System improvements and enhancements"
    }
  },
  "features": {
    "tasks": [
      {
        "id": 1,
        "title": "Implement Recipe Management API Backend",
        "description": "Create a backend API with full CRUD functionality to manage recipe content stored as markdown files in the `/content/recipes/` directory.",
        "details": "This task involves building the core backend service for recipe management.\n\n**1. Project Setup:**\n   - Initialize a new Node.js project.\n   - Install necessary dependencies: Express for the server, `fs-extra` for file system operations, `gray-matter` for parsing markdown frontmatter, and `marked` or a similar library for converting markdown body to HTML.\n\n**2. Markdown Parsing Service:**\n   - Create a utility service to handle all interactions with markdown files.\n   - Implement a function to parse a markdown file's content. It should use `gray-matter` to separate the frontmatter (metadata like title, author, image, tags) from the main markdown content (ingredients, instructions).\n   - The service should convert the markdown body into a structured format (e.g., HTML string).\n\n**3. Recipe Controller:**\n   - Create a `recipeController.js` file to house the logic for handling recipe data.\n   - **`getAllRecipes(req, res)`**: Reads all `.md` files from `/content/recipes/`. For each file, it parses the frontmatter to create a summary object (e.g., `{ slug, title, author, image }`) and returns an array of these objects.\n   - **`getRecipeBySlug(req, res)`**: Retrieves the `slug` from the request parameters. Reads the corresponding file (e.g., `/content/recipes/my-recipe.md`), parses the full file (frontmatter and body), and returns the complete recipe object as JSON.\n   - **`createRecipe(req, res)`**: Takes recipe data from the request body. Generates a URL-friendly slug from the title. Formats the data into a markdown string with frontmatter. Saves the string as a new file (e.g., `[slug].md`) in the `/content/recipes/` directory.\n   - **`updateRecipe(req, res)`**: Retrieves the `slug` from parameters and updated data from the request body. Reads the existing file, replaces its content with the updated, formatted markdown, and saves it.\n   - **`deleteRecipe(req, res)`**: Retrieves the `slug` from parameters and deletes the corresponding `.md` file from the filesystem.\n\n**4. API Routes:**\n   - Create a `recipeRoutes.js` file to define the API endpoints.\n   - `GET /api/recipes`: Maps to `getAllRecipes`.\n   - `POST /api/recipes`: Maps to `createRecipe`.\n   - `GET /api/recipes/:slug`: Maps to `getRecipeBySlug`.\n   - `PUT /api/recipes/:slug`: Maps to `updateRecipe`.\n   - `DELETE /api/recipes/:slug`: Maps to `deleteRecipe`.\n\n**5. Error Handling:**\n   - Implement robust error handling. For example, return a 404 Not Found error if a requested recipe slug does not correspond to a file. Return a 400 Bad Request for invalid input data.",
        "testStrategy": "**1. Setup:**\n   - Create a temporary test directory (e.g., `/content/recipes_test/`) with a few sample recipe markdown files.\n\n**2. API Endpoint Testing (using Postman, Insomnia, or automated tests with Supertest):**\n   - **`GET /api/recipes`**: Send a GET request. Verify the response is a 200 OK. The response body should be a JSON array containing summary objects for all recipes in the test directory.\n   - **`POST /api/recipes`**: Send a POST request with a valid JSON payload for a new recipe. Verify the response is a 201 Created. Check the test directory to confirm that a new `.md` file with the correct slug and content has been created.\n   - **`GET /api/recipes/:slug`**: Send a GET request using the slug of an existing recipe. Verify the response is a 200 OK and the body contains the full, parsed JSON for that recipe. Test with a non-existent slug and verify a 404 Not Found response.\n   - **`PUT /api/recipes/:slug`**: Send a PUT request with an updated title or other fields. Verify a 200 OK response. Manually inspect the corresponding `.md` file to ensure its content has been updated correctly.\n   - **`DELETE /api/recipes/:slug`**: Send a DELETE request for an existing recipe. Verify a 200 OK or 204 No Content response. Check the test directory to confirm the file has been removed.\n\n**3. Unit Testing:**\n   - Write unit tests for the markdown parsing utility to ensure it correctly separates frontmatter and content from a sample markdown string.\n   - Write unit tests for the controller functions, mocking file system calls (`fs`) to test the logic in isolation.",
        "status": "done",
        "dependencies": [],
        "priority": "low",
        "subtasks": [
          {
            "id": 1,
            "title": "Project Initialization and Basic Server Setup",
            "description": "Initialize a new Node.js project, install all required dependencies (Express, fs-extra, gray-matter, marked), and set up a basic Express server structure.",
            "dependencies": [],
            "details": "Create a `package.json` file using `npm init`. Install Express, fs-extra, gray-matter, and marked. Create a main server file (e.g., `index.js` or `app.js`) that initializes an Express app and makes it listen on a configured port. Set up a basic file structure (e.g., `/src`, `/src/controllers`, `/src/routes`, `/src/services`) and the `/content/recipes/` directory.",
            "status": "done",
            "testStrategy": "Run the server using `node index.js`. Verify that the server starts without errors and logs a message indicating it's listening on the correct port. Create a simple root route (`/`) that returns a 'Server is running' message to confirm Express is working."
          },
          {
            "id": 2,
            "title": "Develop Markdown Parsing and File I/O Service",
            "description": "Create a dedicated service module to handle all file system interactions and markdown parsing logic for recipe files.",
            "dependencies": [
              "1.1"
            ],
            "details": "Create a `markdown.service.js` file. Implement a function `parseMarkdownFile(filePath)` that reads a file, uses `gray-matter` to separate frontmatter and content, and uses `marked` to convert the markdown body to HTML. Implement a function `writeMarkdownFile(filePath, data)` that takes a recipe object, formats it into a markdown string with frontmatter, and writes it to the specified file path using `fs-extra`.",
            "status": "done",
            "testStrategy": "Create unit tests for the service. Test the `parseMarkdownFile` function with a sample markdown file to ensure it correctly extracts frontmatter and converts the body to HTML. Test the `writeMarkdownFile` function by writing a data object to a temporary file and then reading it back to verify the content is correctly formatted."
          },
          {
            "id": 3,
            "title": "Implement Read Endpoints (List and Retrieve Recipes)",
            "description": "Create the controller logic and API routes for fetching all recipes and a single recipe by its slug.",
            "dependencies": [
              "1.2"
            ],
            "details": "In `recipeController.js`, implement `getAllRecipes` to read all `.md` files from `/content/recipes/`, parse only the frontmatter for each, and return a summary list. Implement `getRecipeBySlug` to read and parse a specific recipe file completely. In `recipeRoutes.js`, define `GET /api/recipes` and `GET /api/recipes/:slug` and map them to the corresponding controller functions.",
            "status": "done",
            "testStrategy": "Using Postman or Supertest, send a `GET` request to `/api/recipes`. Verify it returns a 200 status and an array of recipe summaries. Send a `GET` request to `/api/recipes/:slug` with a valid slug from the test content directory. Verify it returns a 200 status and the full recipe JSON object."
          },
          {
            "id": 4,
            "title": "Implement Write Endpoints (Create, Update, Delete Recipes)",
            "description": "Create the controller logic and API routes for creating, updating, and deleting recipes.",
            "dependencies": [
              "1.2"
            ],
            "details": "In `recipeController.js`, implement `createRecipe` to generate a slug from the title, format request body data into markdown, and save a new file. Implement `updateRecipe` to overwrite an existing file with new data. Implement `deleteRecipe` to remove a file. In `recipeRoutes.js`, define `POST /api/recipes`, `PUT /api/recipes/:slug`, and `DELETE /api/recipes/:slug`.",
            "status": "done",
            "testStrategy": "Use a temporary test directory. **Create:** Send a `POST` request with recipe data; verify a 201 status and that the file is created on disk. **Update:** Send a `PUT` request to the new slug; verify a 200 status and that the file content is updated. **Delete:** Send a `DELETE` request to the slug; verify a 200 or 204 status and that the file is removed from the disk."
          },
          {
            "id": 5,
            "title": "Implement Robust Error Handling and Finalize API",
            "description": "Implement centralized error handling middleware and integrate all components (routes, controllers, services) into the main application.",
            "dependencies": [
              "1.3",
              "1.4"
            ],
            "details": "Create a global error handling middleware in Express. Refine controller logic to catch specific errors (e.g., file not found from `fs-extra`) and pass them to the error handler. The handler should return appropriate HTTP status codes (404, 400, 500) and JSON error messages. Ensure the main `app.js` correctly uses the recipe routes middleware (`app.use('/api/recipes', recipeRoutes)`).",
            "status": "done",
            "testStrategy": "Test edge cases. Request a non-existent slug for `GET`, `PUT`, and `DELETE` endpoints and verify a 404 response. Send a `POST` request with invalid or missing data (e.g., no title) and verify a 400 Bad Request response. Manually trigger a file system error (e.g., by changing permissions on the content directory) and verify a 500 Internal Server Error is returned gracefully."
          }
        ]
      },
      {
        "id": 2,
        "title": "Implement Production Workflow API",
        "description": "Create a backend API to expose and manage production workflows defined in YAML files from the '/backend/bakery/processes/' directory. This involves creating a controller, YAML parsing service, and API routes for listing and retrieving workflow details.",
        "details": "This task focuses on making production process definitions, stored as YAML, accessible via a RESTful API.\n\n**1. Dependency Installation:**\n   - Add a YAML parsing library to the project. `js-yaml` is recommended.\n   - `npm install js-yaml`\n\n**2. YAML Parsing Service:**\n   - Create a new service file, e.g., `backend/src/services/workflow.service.js`.\n   - This service will be responsible for all file system interactions with the `/backend/bakery/processes/` directory.\n   - Implement a function `getAllWorkflows()` that reads all `.yml` or `.yaml` files, parses them, and returns an array of workflow summaries (e.g., id, name, description).\n   - Implement a function `getWorkflowById(id)` that finds and parses a specific YAML file based on its filename (e.g., 'bake-bread' for 'bake-bread.yml').\n   - Include robust error handling for file-not-found and YAML parsing errors.\n\n**3. Workflow Controller:**\n   - Create a new controller file, e.g., `backend/src/controllers/workflow.controller.js`.\n   - Create a `listWorkflows` handler that uses the `workflow.service` to get all workflow summaries and sends them as a JSON response.\n   - Create a `getWorkflow` handler that takes a workflow ID from the request parameters, uses the service to fetch the full workflow details, and sends them as a JSON response. Handle cases where the workflow is not found (404).\n\n**4. API Routes:**\n   - Create a new routes file, e.g., `backend/src/routes/workflow.routes.js`.\n   - Define the following endpoints:\n     - `GET /api/workflows`: Maps to the `listWorkflows` controller function.\n     - `GET /api/workflows/:workflowId`: Maps to the `getWorkflow` controller function.\n   - Integrate these new routes into the main application file (e.g., `app.js` or `server.js`) under the `/api` prefix.",
        "testStrategy": "**1. Setup:**\n   - Create a temporary test directory, e.g., `/backend/bakery/processes_test/`.\n   - Create at least three sample workflow YAML files in this directory.\n     - `process-a.yml` (valid)\n     - `process-b.yml` (valid)\n     - `process-c.yml` (invalid syntax)\n     - `not-a-workflow.txt` (to be ignored)\n   - Point the `workflow.service` to this directory during tests.\n\n**2. Sample Valid YAML Structure:**\n   ```yaml\n   id: bake-bread\n   name: Standard Bread Baking Workflow\n   description: The complete process from mixing to cooling for a standard loaf.\n   author: 'Jane Doe'\n   steps:\n     - id: mixing\n       name: Mixing Ingredients\n       duration: '15m'\n     - id: proofing\n       name: First Rise\n       duration: '1h'\n   ```\n\n**3. API Endpoint Testing (using Supertest or Postman):**\n   - **`GET /api/workflows`**: Send a GET request. Verify the response is a 200 OK. The response body should be a JSON array containing summaries for `process-a` and `process-b`, but not `process-c` or the `.txt` file. Verify the content of the summaries.\n   - **`GET /api/workflows/process-a`**: Send a GET request with a valid ID. Verify the response is a 200 OK and the body contains the full, parsed JSON object for `process-a.yml`.\n   - **`GET /api/workflows/non-existent-process`**: Send a GET request with an ID that does not correspond to a file. Verify the response is a 404 Not Found.\n   - **`GET /api/workflows/process-c`**: Send a GET request for the workflow with invalid YAML. Verify the server responds with a 500 Internal Server Error and a meaningful error message.",
        "status": "done",
        "dependencies": [
          1
        ],
        "priority": "low",
        "subtasks": [
          {
            "id": 1,
            "title": "Setup and Dependency Installation for Workflow API",
            "description": "Install the necessary YAML parsing library and create the initial empty files for the service, controller, and routes to establish the feature's structure.",
            "dependencies": [],
            "details": "Add the `js-yaml` library to the project's dependencies by running `npm install js-yaml`. Create the following empty files to house the new logic: `backend/src/services/workflow.service.js`, `backend/src/controllers/workflow.controller.js`, and `backend/src/routes/workflow.routes.js`.",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "Implement `getAllWorkflows` Service Function",
            "description": "Develop the service logic to read all workflow definition files from the specified directory, parse them, and return a summarized list.",
            "dependencies": [],
            "details": "In `workflow.service.js`, implement the `getAllWorkflows()` function. This function must read the contents of the `/backend/bakery/processes/` directory, filter for files with `.yml` or `.yaml` extensions, parse each file's content using `js-yaml`, and return an array of workflow summary objects (e.g., containing id, name, description). Include error handling for directory access and YAML parsing errors.",
            "status": "done",
            "testStrategy": "Unit test the `getAllWorkflows` function. Use a mock file system to provide a set of test YAML files, including one with invalid syntax. Verify that the function returns correct summaries for valid files and gracefully handles or throws an error for the invalid file."
          },
          {
            "id": 3,
            "title": "Implement `getWorkflowById` Service Function",
            "description": "Develop the service logic to retrieve and parse a single, specific workflow file based on a provided ID.",
            "dependencies": [],
            "details": "In `workflow.service.js`, implement the `getWorkflowById(id)` function. This function will take a workflow ID (which corresponds to the filename without the extension), construct the full file path, read the file, and return the fully parsed YAML content as a JavaScript object. Implement robust error handling to distinguish between 'file not found' errors and 'YAML parsing' errors.",
            "status": "done",
            "testStrategy": "Unit test the `getWorkflowById` function. Test the successful retrieval of a valid workflow. Crucially, test the failure case by requesting an ID that does not correspond to a file, and ensure the function signals a 'not found' condition that the controller can use to return a 404 status."
          },
          {
            "id": 4,
            "title": "Create Workflow Controller and API Routes",
            "description": "Implement the controller and routing layers to expose the workflow service functions via a RESTful API.",
            "dependencies": [],
            "details": "In `workflow.controller.js`, create two handlers: `listWorkflows` and `getWorkflow`. The `listWorkflows` handler will call `workflow.service.getAllWorkflows()` and send the result as a JSON response. The `getWorkflow` handler will extract the `workflowId` from request parameters, call `workflow.service.getWorkflowById()`, and send the result or a 404 Not Found response. In `workflow.routes.js`, define the `GET /api/workflows` and `GET /api/workflows/:workflowId` endpoints and map them to their respective controller handlers.",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 5,
            "title": "Integrate Routes and Prepare Test Environment",
            "description": "Integrate the new workflow routes into the main application server and set up the test directory and sample files required for end-to-end testing.",
            "dependencies": [],
            "details": "In the main application entry point (e.g., `app.js` or `server.js`), import the workflow router from `workflow.routes.js` and mount it under the `/api` prefix. Following the test strategy, create the test directory `/backend/bakery/processes_test/` and populate it with sample files: `process-a.yml` (valid), `process-b.yml` (valid), `process-c.yml` (invalid syntax), and `not-a-workflow.txt`.",
            "status": "done",
            "testStrategy": "Perform integration testing using a tool like Supertest or Postman. Verify that `GET /api/workflows` returns a 200 status with a list of workflows. Verify that `GET /api/workflows/process-a` returns a 200 status with the correct workflow details. Verify that `GET /api/workflows/non-existent-process` returns a 404 status."
          }
        ]
      },
      {
        "id": 3,
        "title": "Implement Inventory Management Backend",
        "description": "Create the backend system for inventory management, including a data model, API controllers, and routes to track and manage stock levels of ingredients.",
        "details": "1. **Database Model Setup:**\n   - Define an Inventory Item schema. If using Mongoose with MongoDB, create `backend/src/models/inventory.model.js`.\n   - The schema should include fields like: `name` (String, required, unique), `sku` (String, unique), `description` (String), `quantity` (Number, required, default: 0, min: 0), `unit` (String, e.g., 'kg', 'liters', 'units'), `lowStockThreshold` (Number, default: 0), `updatedAt` (Date).\n\n2. **Service Layer:**\n   - Create `backend/src/services/inventory.service.js` to encapsulate all database logic.\n   - Implement functions for: `createItem`, `getAllItems`, `getItemById`, `updateItemDetails`, and `adjustStockLevel`.\n   - The `adjustStockLevel` function should handle both adding and subtracting from the quantity and include logic to prevent the quantity from going below zero.\n\n3. **API Controller:**\n   - Create `backend/src/controllers/inventory.controller.js`.\n   - Implement controller functions that use the inventory service to handle incoming HTTP requests. These functions will manage request/response cycles, call the appropriate service methods, and handle errors (e.g., validation errors, item not found).\n\n4. **API Routes:**\n   - Create `backend/src/routes/inventory.routes.js` and integrate it into the main Express app.\n   - Define the following RESTful endpoints:\n     - `POST /api/inventory`: Add a new inventory item. Body should match the model.\n     - `GET /api/inventory`: List all inventory items. Support pagination and filtering (e.g., `?lowStock=true`).\n     - `GET /api/inventory/:id`: Retrieve a single inventory item by its ID.\n     - `PUT /api/inventory/:id`: Update an item's non-stock details (e.g., name, description, threshold).\n     - `PATCH /api/inventory/:id/stock`: Adjust the stock quantity. Body should be like `{ \"change\": 50 }` (to add) or `{ \"change\": -25 }` (to subtract).\n\n5. **Configuration:**\n   - Ensure database connection strings and other configurations are managed through environment variables.",
        "testStrategy": "1. **Setup:**\n   - Configure a separate test database.\n   - Use a test runner like Jest with Supertest for integration testing.\n   - Create setup and teardown scripts to seed the test database before tests and clear it afterward.\n\n2. **Unit Tests:**\n   - Write unit tests for the `inventory.service.js`.\n   - Mock the database model to test the service logic in isolation.\n   - Test edge cases, such as trying to adjust stock to a negative value or finding a non-existent item.\n\n3. **Integration / API Endpoint Testing:**\n   - **`POST /api/inventory`**: Verify that an item can be created with valid data (201 response) and that requests with invalid/missing data are rejected (400 response).\n   - **`GET /api/inventory`**: Verify that the endpoint returns a list of all items (200 response).\n   - **`GET /api/inventory/:id`**: Verify retrieval of a specific item (200 response) and failure for a non-existent ID (404 response).\n   - **`PUT /api/inventory/:id`**: Verify that an item's details can be updated successfully.\n   - **`PATCH /api/inventory/:id/stock`**: \n     - Send a positive `change` value and verify the quantity increases.\n     - Send a negative `change` value and verify the quantity decreases.\n     - Send a negative `change` value that would result in a negative quantity and verify the request is rejected (e.g., 409 Conflict or 400 Bad Request) and the quantity remains unchanged.",
        "status": "done",
        "dependencies": [
          1,
          2
        ],
        "priority": "low",
        "subtasks": [
          {
            "id": 1,
            "title": "Define Inventory Model and Configure Database",
            "description": "Create the Mongoose schema for inventory items and configure the database connection using environment variables.",
            "dependencies": [],
            "details": "Create the file `backend/src/models/inventory.model.js`. Define the schema with all specified fields: `name`, `sku`, `description`, `quantity`, `unit`, `lowStockThreshold`, and `updatedAt`, including their types, constraints (required, unique, min), and default values. Ensure the application's database connection string is loaded from a `.env` file.\n<info added on 2025-08-01T12:07:54.762Z>\nThe model was created at `backend/models/Inventory.js` and includes custom instance methods (`isLowStock`, `needsReorder`, `adjustStock`). A comprehensive unit test suite with 21 passing tests was created in `tests/unit/inventoryModel.test.js`. The model has been added to the `models/index.js` exports, and the database configuration is confirmed to be using SQLite.\n</info added on 2025-08-01T12:07:54.762Z>",
            "status": "done",
            "testStrategy": "Write a unit test for the Mongoose model to verify that default values are set correctly and that validation constraints (e.g., `required`, `min: 0`) are enforced."
          },
          {
            "id": 2,
            "title": "Implement Inventory Service Layer",
            "description": "Create the service layer to encapsulate all database logic for inventory management.",
            "dependencies": [
              "3.1"
            ],
            "details": "Create the file `backend/src/services/inventory.service.js`. Implement all the core data manipulation functions: `createItem`, `getAllItems`, `getItemById`, `updateItemDetails`, and `adjustStockLevel`. The `adjustStockLevel` function must contain logic to handle both addition and subtraction, and critically, prevent the quantity from ever becoming negative.\n<info added on 2025-08-01T12:11:09.268Z>\nThe implementation exceeds the initial requirements by adding filtering support to `getAllItems`, a `deleteItem` method (soft delete), and several utility methods (`getItemsNeedingReorder`, `getLowStockItems`, `bulkAdjustStock`). A comprehensive unit test suite with 27 passing tests has also been created in `tests/unit/inventoryService.test.js` to validate all functionality and edge cases.\n</info added on 2025-08-01T12:11:09.268Z>",
            "status": "done",
            "testStrategy": "Write unit tests for each service function, mocking the Mongoose model. Pay special attention to testing the `adjustStockLevel` function's edge cases, such as subtracting to exactly zero and attempting to subtract more than the available quantity."
          },
          {
            "id": 3,
            "title": "Build API Controller and Define Routes",
            "description": "Create the API controller to handle HTTP requests and define all the RESTful routes for the inventory endpoints.",
            "dependencies": [
              "3.2"
            ],
            "details": "Create `backend/src/controllers/inventory.controller.js` to mediate between routes and the service layer, handling request/response objects and errors. Create `backend/src/routes/inventory.routes.js` and define all five required endpoints: `POST /api/inventory`, `GET /api/inventory`, `GET /api/inventory/:id`, `PUT /api/inventory/:id`, and `PATCH /api/inventory/:id/stock`. Integrate this router into the main Express application.\n<info added on 2025-08-01T12:16:31.265Z>\nImplementation includes the five required endpoints plus additional utility endpoints for `low-stock`, `needs-reorder`, and `bulk-adjust`. All routes have been protected with authentication middleware.\n</info added on 2025-08-01T12:16:31.265Z>",
            "status": "done",
            "testStrategy": "This subtask is primarily about wiring. Verification will happen in subsequent integration tests. Ensure the routes are correctly registered and accessible by the application."
          },
          {
            "id": 4,
            "title": "Implement and Test Core CRUD Endpoints",
            "description": "Connect and test the endpoints for creating a new item, retrieving a single item, and updating an item's details.",
            "dependencies": [
              "3.3"
            ],
            "details": "Wire the controller functions to the corresponding service methods for the `POST /api/inventory`, `GET /api/inventory/:id`, and `PUT /api/inventory/:id` routes. Implement request body validation and error handling (e.g., 'Item not found' 404 responses).\n<info added on 2025-08-01T12:18:30.255Z>\nComprehensive integration tests (16 passing) have been created in `tests/integration/inventoryAPI.test.js`. These tests validate the full functionality, including error handling and validation, for the core CRUD endpoints: `POST /api/inventory`, `GET /api/inventory/:id`, `PUT /api/inventory/:id`, and `DELETE /api/inventory/:id`.\n</info added on 2025-08-01T12:18:30.255Z>",
            "status": "done",
            "testStrategy": "Use a test runner like Jest with Supertest to write integration tests for each endpoint. Test for successful creation (201), retrieval (200), and update (200). Also, test for error cases like invalid input (400) or requesting a non-existent ID (404)."
          },
          {
            "id": 5,
            "title": "Implement List Endpoint with Filtering and Stock Adjustment Endpoint",
            "description": "Implement the final two endpoints: listing all items with advanced filtering and adjusting an item's stock level.",
            "dependencies": [
              "3.3"
            ],
            "details": "For the `GET /api/inventory` route, add logic to the service and controller to handle pagination and the `?lowStock=true` query parameter. The filter should return items where `quantity <= lowStockThreshold`. For the `PATCH /api/inventory/:id/stock` route, implement the logic to process a body like `{ \"change\": -10 }` to call the `adjustStockLevel` service function.\n<info added on 2025-08-01T12:20:30.457Z>\nAdded a comprehensive integration test suite in `tests/integration/inventoryAdvancedAPI.test.js`. The 21 passing tests cover the advanced `GET /api/inventory` endpoint (validating pagination, `lowStock`, category, and search filters) and the `PATCH /api/inventory/:id/stock` endpoint (validating stock increases, decreases, and insufficient stock error handling). The suite also includes tests for special endpoints like low-stock, needs-reorder, and bulk-adjust.\n</info added on 2025-08-01T12:20:30.457Z>",
            "status": "done",
            "testStrategy": "Write integration tests for `GET /api/inventory` with and without query parameters to verify filtering and pagination work as expected. Write integration tests for the `PATCH` endpoint, testing positive changes, negative changes, and an attempt to make the stock negative (which should result in a 400 Bad Request)."
          }
        ]
      },
      {
        "id": 4,
        "title": "Remediate Hardcoded JWT Secret Vulnerability",
        "description": "Replace the hardcoded JWT secret with an environment variable to resolve a critical security vulnerability. This involves integrating support for .env files and updating all JWT signing and verification logic.",
        "status": "done",
        "dependencies": [],
        "priority": "medium",
        "details": "This task addresses a critical security flaw where a JWT secret is hardcoded in the source code. The secret must be externalized into environment variables.\n\n**1. Dependency Installation:**\n   - Add the `dotenv` package to manage environment variables from a `.env` file.\n   - Run: `npm install dotenv`\n\n**2. Environment Configuration:**\n   - Create a `.gitignore` entry for `.env` files to prevent secrets from being committed to version control. Ensure `*.env` is added.\n   - Create a file named `.env` in the project root.\n   - Add a secure, randomly generated secret to the `.env` file. Example: `JWT_SECRET=your-super-strong-randomly-generated-secret-key-here`\n   - Create a `.env.example` file that mirrors `.env` but with placeholder values. This file will be committed to source control. Example: `JWT_SECRET=`\n\n**3. Application Integration:**\n   - In the main application entry point (e.g., `server.js` or `app.js`), load and configure `dotenv` at the very top of the file:\n     ```javascript\n     require('dotenv').config();\n     ```\n   - Implement a startup check to ensure the application fails fast if the secret is not configured. This prevents running in an insecure state:\n     ```javascript\n     if (!process.env.JWT_SECRET) {\n       console.error('FATAL ERROR: JWT_SECRET is not defined in the environment variables.');\n       process.exit(1);\n     }\n     ```\n\n**4. Code Refactoring:**\n   - Locate all instances where JWTs are signed or verified (e.g., in `authMiddleware.js`, `auth.service.js`, or user login controllers).\n   - Replace the hardcoded secret string (e.g., `'your_secret_key'`) with the environment variable `process.env.JWT_SECRET`.\n   - Example in `authMiddleware.js`:\n     ```javascript\n     // Before\n     jwt.verify(token, 'your_secret_key', (err, user) => { ... });\n\n     // After\n     jwt.verify(token, process.env.JWT_SECRET, (err, user) => { ... });\n     ```\n\n**5. Documentation Update:**\n   - Update the project's `README.md` file with a new \"Environment Setup\" section.\n   - Instruct developers to copy `.env.example` to `.env` and populate it with their own secrets.\n   - Provide a command to generate a suitable secret, e.g., `node -e \"console.log(require('crypto').randomBytes(32).toString('hex'))\"`.",
        "testStrategy": "**1. Configuration Testing:**\n   - Create an automated test that runs the application startup script without the `JWT_SECRET` environment variable set. Verify that the application logs a fatal error and the process exits with a non-zero status code.\n\n**2. Integration Testing (Authentication Flow):**\n   - Ensure all existing authentication-related tests (e.g., user login, token generation) continue to pass.\n   - Create a new integration test suite for protected endpoints:\n     a. Set a known `JWT_SECRET` in the test environment.\n     b. Authenticate a test user to obtain a valid JWT.\n     c. Use the token to successfully access a protected API endpoint and assert a 200 OK status.\n     d. Attempt to access the same endpoint using a token signed with the old, hardcoded secret. Assert that the request is rejected with a 401 Unauthorized status.\n     e. Attempt to access the endpoint with no token. Assert a 401 Unauthorized status.\n\n**3. Manual Verification:**\n   - Delete any existing `.env` file.\n   - Follow the updated `README.md` setup instructions from the perspective of a new developer.\n   - Verify that copying `.env.example` to `.env` and populating the `JWT_SECRET` allows the application to start and function correctly.\n   - Run `git status` to confirm that the `.env` file is not tracked by Git.",
        "subtasks": []
      },
      {
        "id": 5,
        "title": "Implement API Request Validation and Sanitization",
        "description": "Integrate `express-validator` to create a robust validation and sanitization layer for all API endpoints, ensuring data integrity and providing consistent error handling for invalid requests.",
        "status": "done",
        "dependencies": [],
        "priority": "medium",
        "details": "This task involves implementing middleware to validate and sanitize incoming API request data. This will prevent malformed data from reaching the service layer and improve application security and stability.\n\n**1. Dependency Installation:**\n   - Add the `express-validator` package to the project.\n   - Run: `npm install express-validator`\n\n**2. Validation Error Handling Middleware:**\n   - Create a new middleware file, e.g., `backend/src/middleware/validator.middleware.js`.\n   - This middleware will use `validationResult` from `express-validator` to check for errors. If errors exist, it should stop the request chain and respond with a 422 Unprocessable Entity status and a consistent JSON error format.\n   - Example error handler:\n     ```javascript\n     const { validationResult } = require('express-validator');\n     const handleValidationErrors = (req, res, next) => {\n       const errors = validationResult(req);\n       if (!errors.isEmpty()) {\n         return res.status(422).json({ errors: errors.array() });\n       }\n       next();\n     };\n     module.exports = { handleValidationErrors };\n     ```\n\n**3. Validation Schemas:**\n   - Create a new directory `backend/src/validators/` to store validation logic, keeping route files clean.\n   - Create separate files for each resource's validation rules.\n   - **Inventory Validator (`inventory.validator.js`):** For endpoints from Task 3.\n     ```javascript\n     const { body } = require('express-validator');\n     const inventoryCreationRules = () => [\n       body('name').trim().notEmpty().withMessage('Item name is required.'),\n       body('quantity').isInt({ min: 0 }).withMessage('Quantity must be a non-negative integer.'),\n       body('unit').trim().notEmpty().withMessage('Unit is required.'),\n       body('lowStockThreshold').optional().isInt({ min: 0 })\n     ];\n     ```\n   - **User Validator (`user.validator.js`):** For user registration and login.\n     ```javascript\n     const userRegistrationRules = () => [\n       body('email').isEmail().normalizeEmail().withMessage('A valid email is required.'),\n       body('password').isLength({ min: 8 }).withMessage('Password must be at least 8 characters long.')\n     ];\n     const loginRules = () => [\n       body('email').isEmail().normalizeEmail(),\n       body('password').notEmpty()\n     ];\n     ```\n   - Create similar validation schema files for other resources like Products and Orders as they are developed.\n\n**4. Route Integration:**\n   - Apply the validation rules and the error handling middleware to the relevant routes in the Express router files.\n   - Example for an inventory route:\n     ```javascript\n     const express = require('express');\n     const router = express.Router();\n     const inventoryController = require('../controllers/inventory.controller');\n     const { inventoryCreationRules } = require('../validators/inventory.validator');\n     const { handleValidationErrors } = require('../middleware/validator.middleware');\n\n     router.post('/', inventoryCreationRules(), handleValidationErrors, inventoryController.createItem);\n     ```\n\n**5. Sanitization:**\n   - Ensure all string inputs are sanitized to prevent XSS attacks and normalize data. Use methods like `.trim()` to remove whitespace and `.escape()` to convert HTML special characters.",
        "testStrategy": "Testing will focus on verifying that the validation and sanitization logic correctly rejects invalid data and allows valid data, while checking for a consistent error response format.\n\n**1. Unit Testing (Optional but Recommended):**\n   - Write unit tests for individual validation schemas to ensure they function correctly in isolation.\n\n**2. Integration Testing (Jest & Supertest):**\n   - For each protected endpoint, create a suite of tests to cover various invalid input scenarios.\n   - **Inventory Endpoint (`POST /api/inventory`):**\n     - **Missing Fields:** Send a request without the `name` or `quantity` field. Expect a 422 status and an error message indicating the field is required.\n     - **Invalid Data Type:** Send `quantity: 'abc'`. Expect a 422 status and a type error message.\n     - **Constraint Violation:** Send `quantity: -5`. Expect a 422 status and a constraint violation message.\n     - **Sanitization Check:** Send `name: '  Flour  '`. Verify that the created item's name in the database is `'Flour'`. Send a name with script tags like `<script>alert(1)</script>` and verify it is properly escaped.\n\n   - **User Registration Endpoint (`POST /api/users/register`):**\n     - **Invalid Email:** Send `email: 'not-an-email'`. Expect a 422 status.\n     - **Short Password:** Send `password: '123'`. Expect a 422 status with a message about minimum length.\n\n**3. Error Response Format Verification:**\n   - In all failing test cases, assert that the HTTP response status is 422.\n   - Assert that the response body strictly matches the defined error format, e.g., `{\"errors\": [{\"type\": \"field\", \"msg\": \"...\", ...}]}`.\n\n**4. Happy Path Testing:**\n   - For every endpoint, include a test with a perfectly valid request payload to ensure it passes validation and receives a 2xx success response.",
        "subtasks": []
      },
      {
        "id": 6,
        "title": "Implement API Rate Limiting and Security Headers",
        "description": "Integrate express-rate-limit and helmet.js to protect API endpoints against brute-force attacks and common web vulnerabilities, with distinct limits for authentication and general API routes.",
        "details": "This task focuses on hardening the API by introducing essential security middleware.\n\n1. **Dependency Installation:**\n   - Add the necessary packages for rate limiting and security headers.\n   - Run: `npm install express-rate-limit helmet`\n\n2. **Helmet.js Integration:**\n   - In the main application entry point (e.g., `backend/src/app.js`), import `helmet`.\n   - Apply it as a global middleware near the top of the middleware stack to ensure all responses receive security headers: `app.use(helmet());`\n   - The default configuration is robust and suitable for most applications.\n\n3. **Rate Limiter Configuration:**\n   - Create a new middleware configuration file, e.g., `backend/src/middleware/rateLimit.middleware.js`.\n   - **General API Limiter:** Define a rate limiter for general API traffic.\n     - `const apiLimiter = rateLimit({ windowMs: 15 * 60 * 1000, max: 100, standardHeaders: true, legacyHeaders: false, message: { error: 'Too many requests, please try again after 15 minutes.' } });`\n   - **Authentication Limiter:** Define a stricter rate limiter for sensitive authentication endpoints (e.g., login, register, password reset).\n     - `const authLimiter = rateLimit({ windowMs: 15 * 60 * 1000, max: 10, standardHeaders: true, legacyHeaders: false, message: { error: 'Too many authentication attempts, please try again after 15 minutes.' } });`\n\n4. **Middleware Application:**\n   - In `app.js`, apply the `apiLimiter` to all routes under `/api/`: `app.use('/api/', apiLimiter);`\n   - In the authentication router file (e.g., `backend/src/routes/auth.routes.js`), apply the `authLimiter` specifically to the relevant endpoints. This will override the global limiter for these routes.\n     - Example: `router.post('/login', authLimiter, authController.login);`\n   - Ensure rate limiters are registered before the main route handlers.",
        "testStrategy": "Testing will verify that both security headers and rate limits are correctly applied and enforced.\n\n1. **Security Header Verification:**\n   - Use a tool like `curl` (`curl -I http://localhost:PORT/api/recipes`) or browser developer tools to inspect the response headers of any API endpoint.\n   - Confirm the presence of key security headers added by Helmet, such as `Strict-Transport-Security`, `X-Content-Type-Options: nosniff`, `X-Frame-Options: SAMEORIGIN`, and `Content-Security-Policy`.\n\n2. **General Rate Limit Test:**\n   - Create an automated script (e.g., using Jest and Supertest, or a simple shell loop) to send 101 requests to a general endpoint like `GET /api/recipes` in quick succession.\n   - Assert that the first 100 requests receive a `200 OK` status.\n   - Assert that the 101st request receives a `429 Too Many Requests` status code and the specified JSON error message.\n   - Inspect the headers of a successful response to verify the presence and values of `RateLimit-Limit`, `RateLimit-Remaining`, and `RateLimit-Reset`.\n\n3. **Authentication Rate Limit Test:**\n   - Write a similar script to send 11 requests to a sensitive endpoint like `POST /api/auth/login` (with dummy data).\n   - Assert that the first 10 requests receive a non-429 status (e.g., `401 Unauthorized`).\n   - Assert that the 11th request receives a `429 Too Many Requests` status, confirming the stricter limit is active.\n\n4. **IP Isolation Test:**\n   - If possible, execute the test scripts from two different network locations/IPs to confirm that rate limits are tracked independently for each IP address.",
        "status": "done",
        "dependencies": [
          4
        ],
        "priority": "medium",
        "subtasks": []
      },
      {
        "id": 7,
        "title": "Implement API Documentation with OpenAPI/Swagger",
        "description": "Integrate Swagger UI and JSDoc to generate comprehensive, interactive API documentation from code comments. The documentation will be available at the /api-docs endpoint and cover all existing API routes.",
        "status": "done",
        "dependencies": [
          4,
          5,
          6
        ],
        "priority": "medium",
        "details": "1. **Dependency Installation:**\n   - Add the necessary packages for generating documentation from JSDoc comments and serving it via an Express UI.\n   - Run: `npm install swagger-jsdoc swagger-ui-express`\n\n2. **Swagger Configuration:**\n   - Create a new configuration file, e.g., `backend/src/config/swagger.config.js`.\n   - Inside this file, define the options for `swagger-jsdoc`.\n   - **Definition Object:** Set up the base OpenAPI 3.0 definition including `openapi: '3.0.0'`, `info` (with title, version, description), `servers`, and `components`.\n   - **Components:** Under `components`, define `securitySchemes` for JWT Bearer authentication and reusable `schemas` for data models (e.g., Recipe, InventoryItem) and standard error responses to promote consistency and DRY principles.\n   - **APIs Array:** Specify the path to the files that contain the API endpoint definitions and JSDoc comments (e.g., `['./backend/src/routes/*.js', './backend/src/docs/**/*.yaml']`).\n\n3. **Express Integration:**\n   - In your main application file (`backend/src/app.js`), import `swagger-jsdoc`, `swagger-ui-express`, and your configuration.\n   - Generate the OpenAPI specification: `const swaggerSpec = swaggerJSDoc(options);`\n   - Set up the documentation route: `app.use('/api-docs', swaggerUi.serve, swaggerUi.setup(swaggerSpec));`\n\n4. **JSDoc Annotation for Endpoints:**\n   - Annotate every route in the application's route files using JSDoc comment blocks.\n   - For each endpoint, document the `summary`, `description`, `tags`, `parameters` (path, query), `requestBody` (with `content` type and schema reference), `security` requirements, and all possible `responses`.\n   - **Example Endpoint Annotation:**\n     ```javascript\n     /**\n      * @openapi\n      * /api/inventory/{id}:\n      *   get:\n      *     summary: Retrieve a specific inventory item by ID\n      *     tags: [Inventory]\n      *     security:\n      *       - bearerAuth: []\n      *     parameters:\n      *       - in: path\n      *         name: id\n      *         required: true\n      *         schema:\n      *           type: string\n      *         description: The ID of the inventory item.\n      *     responses:\n      *       '200':\n      *         description: Successful response with the inventory item.\n      *         content:\n      *           application/json:\n      *             schema:\n      *               $ref: '#/components/schemas/InventoryItem'\n      *       '401':\n      *         description: Unauthorized. Token is missing or invalid.\n      *         content:\n      *           application/json:\n      *             schema:\n      *               $ref: '#/components/schemas/ErrorUnauthorized'\n      *       '404':\n      *         description: Inventory item not found.\n      *         content:\n      *           application/json:\n      *             schema:\n      *               $ref: '#/components/schemas/ErrorNotFound'\n      */\n     ```\n   - **Coverage:** Ensure all endpoints from the Recipe, Production Workflow, Inventory, and Auth modules are fully documented, including all CRUD operations and all possible success and error responses (e.g., 200, 201, 400, 401, 403, 404, 429, 500).",
        "testStrategy": "1. **UI and Spec Generation:**\n   - Start the application and navigate to the `/api-docs` endpoint in a browser.\n   - Verify that the Swagger UI loads correctly without any console errors.\n   - Access the raw OpenAPI spec (usually linked from the UI) and ensure it is valid JSON and conforms to the OpenAPI 3.0 standard, for instance by using an online validator.\n\n2. **Content Accuracy Verification:**\n   - Review the generated documentation for completeness. Check that all endpoints are present and grouped under the correct tags (e.g., 'Inventory', 'Recipes', 'Auth').\n   - For each endpoint, confirm that the summary, description, parameters, and security requirements are accurate.\n   - Verify that request body schemas and all possible response schemas (both success and error) are defined and match the actual API behavior established in previous tasks.\n\n3. **Interactive Endpoint Testing:**\n   - Use the \"Try it out\" feature within the Swagger UI.\n   - **Public Endpoints:** Execute a request for a public endpoint and verify it returns the expected 2xx response and payload.\n   - **Protected Endpoints:**\n     - First, attempt to execute a protected endpoint without authentication. Verify it fails with the documented 401/403 error.\n     - Use the \"Authorize\" button to input a valid JWT.\n     - Re-execute the protected endpoint and verify it now succeeds with a 2xx response.\n\n4. **Schema Validation:**\n   - Cross-reference the documented schemas (`#/components/schemas/...`) with the actual data models and validation rules (`express-validator` schemas from Task 5) to ensure they are perfectly aligned.",
        "subtasks": []
      },
      {
        "id": 8,
        "title": "Implement Database Migrations with Sequelize",
        "description": "Establish a robust database migration system using Sequelize CLI to manage schema changes, create initial migrations for existing models, and implement database optimizations like indexes and soft deletes.",
        "status": "done",
        "dependencies": [
          4
        ],
        "priority": "medium",
        "details": "1. **Dependency Installation & Initialization:**\n   - Install Sequelize CLI as a development dependency: `npm install --save-dev sequelize-cli`.\n   - Install the appropriate database driver (e.g., `npm install --save pg pg-hstore` for PostgreSQL).\n   - Initialize the Sequelize project structure: `npx sequelize-cli init`. This will create `config/`, `migrations/`, `models/`, and `seeders/` directories.\n\n2. **Secure Configuration:**\n   - Update `config/config.json` to use environment variables for all database connection details (username, password, database, host, dialect), leveraging the `dotenv` setup from Task #4. This is critical to avoid committing credentials.\n   - Example for the development environment object: `\"use_env_variable\": \"DATABASE_URL\"` or individual fields like `\"username\": process.env.DB_USER`.\n\n3. **Migration File Creation:**\n   - For each existing model (e.g., User, Product, Order, Inventory), generate a new migration file using the CLI: `npx sequelize-cli migration:generate --name create-users-table`.\n   - In the `up` method of each migration, define the table schema using `queryInterface.createTable()`. Specify all columns with correct data types (e.g., `Sequelize.INTEGER`, `Sequelize.STRING`), constraints (`allowNull: false`, `unique: true`), and default values.\n   - In the corresponding `down` method, write the logic to reverse the migration, typically `queryInterface.dropTable('TableName')`.\n\n4. **Implement Soft Deletes & Timestamps:**\n   - In migrations for models that should be soft-deleted (e.g., Users, Orders), add the standard timestamp columns `createdAt`, `updatedAt`, and the soft delete column `deletedAt`.\n   - Example column definitions:\n     `createdAt: { allowNull: false, type: Sequelize.DATE }`\n     `updatedAt: { allowNull: false, type: Sequelize.DATE }`\n     `deletedAt: { allowNull: true, type: Sequelize.DATE }`\n   - Ensure the corresponding Sequelize models are configured with `timestamps: true` and `paranoid: true`.\n\n5. **Define Constraints and Indexes:**\n   - **Foreign Keys:** Within the `queryInterface.createTable()` calls, define foreign key relationships. For example, the `userId` column in the `Orders` table should reference the `Users` table: `userId: { type: Sequelize.INTEGER, references: { model: 'Users', key: 'id' }, onUpdate: 'CASCADE', onDelete: 'SET NULL' }`.\n   - **Indexes:** After creating a table, use `queryInterface.addIndex()` in the `up` method to add indexes to frequently queried fields to improve performance. Target fields like foreign keys (`userId`, `productId`) and common filter fields (`orderDate`, `email`). The `down` method should include `queryInterface.removeIndex()`.\n\n6. **Package.json Scripts:**\n   - Add convenience scripts to `package.json` to streamline the migration workflow:\n     `\"db:migrate\": \"npx sequelize-cli db:migrate\"`\n     `\"db:migrate:undo\": \"npx sequelize-cli db:migrate:undo\"`\n     `\"db:migrate:undo:all\": \"npx sequelize-cli db:migrate:undo:all\"`\n     `\"db:seed:all\": \"npx sequelize-cli db:seed:all\"`",
        "testStrategy": "1. **Migration Execution Test:**\n   - Configure the test environment in `config/config.json` to point to a separate, clean test database.\n   - Run the migration command: `NODE_ENV=test npm run db:migrate`.\n   - Assert that the script executes without any errors and that the command exits with a status code of 0.\n\n2. **Schema Integrity Verification:**\n   - Using a database client (e.g., DBeaver, pgAdmin), connect to the test database.\n   - Verify that all tables defined in the migrations have been created.\n   - Inspect the schema of each table to confirm that all columns, data types, `NOT NULL` constraints, and default values are correctly defined.\n   - Specifically check for the presence of `createdAt`, `updatedAt`, and `deletedAt` columns on relevant tables.\n\n3. **Constraint and Index Validation:**\n   - Examine the table definitions in the database to ensure foreign key constraints are active and correctly link related tables.\n   - Run a database command to list all indexes on a table (e.g., `\\di` in psql) and verify that indexes have been created on the specified columns (e.g., `userId`, `productId`, `email`).\n\n4. **Rollback Test:**\n   - Execute the full rollback script: `NODE_ENV=test npm run db:migrate:undo:all`.\n   - Verify that the script completes successfully.\n   - Connect to the test database again and confirm that all tables created by the migrations have been dropped.",
        "subtasks": []
      }
    ],
    "metadata": {
      "created": "2025-07-31T14:23:50.107Z",
      "updated": "2025-08-01T14:34:16.497Z",
      "description": "New features to be implemented"
    }
  }
}